# CLAUDE.md

このファイルは、このリポジトリでコードを扱う際のClaude Code (claude.ai/code)へのガイダンスを提供します。

## コマンド

### 開発コマンド
```bash
# CLIチャットインターフェースの実行
uv.exe run vizprompt chat ollama "メッセージをここに入力"
uv.exe run vizprompt chat openai "メッセージをここに入力"
uv.exe run vizprompt chat gemini "メッセージをここに入力"

# テストの実行
uv.exe run pytest

# 特定のテストの実行
uv.exe run pytest tests/test_flow_convert_map.py
```

## uv.exeを使用する理由

- プロジェクトはWindows側にあるが、Claude CodeはWSLで実行されるため、Windows側のuvを使用するため。

## アーキテクチャ概要

VizPromptは、チャット履歴をビジュアルフローとして管理するノードベースのインターフェースです。透明性とバージョン管理の互換性のため、データベースの代わりにテキストベースのファイルストレージシステム（XMLノード、YAMLフロー、TSVインデックス）を使用しています。

### 主要なアーキテクチャパターン

1. **ベースマネージャーパターン**: `core/base.py`の`BaseManager`クラスは、UUID/タイムスタンプ追跡を備えた汎用ファイル管理を提供します。`NodeManager`と`FlowManager`の両方がこの基底クラスを継承しています。

2. **DAGフロー構造**: 会話は循環検出機能を持つ有向非巡回グラフ（DAG）として保存されます。`Flow`クラスはカーンのアルゴリズムを使用してトポロジカルソートを行い、会話履歴を再構築します。

3. **ファイル構成**:
   ```
   project/
   ├── nodes/         # 000-999フォルダに整理されたXMLファイル
   │   └── index.tsv  # UUIDからファイル名へのマッピング
   ├── flows/         # YAMLフロー定義
   │   └── index.tsv  # フロー名からUUIDへのマッピング
   └── metadata/      # 将来実装: タグと検索インデックス
   ```

4. **LLM統合**: `BaseGenerator`クラスがLLMプロバイダーの共通インターフェースを提供します。各プロバイダー（OpenAI、Gemini、Ollama）はトークン追跡付きのストリーミングレスポンスを実装しています。

### 重要な実装詳細

- **UUID衝突処理**: UUIDは一意性を保証しません。システムはタイムスタンプ優先度で衝突を解決し、起動時にインデックスを調整します。

- **XMLノード形式**: ノードはプロンプト/レスポンスのフォーマットを保持するためCDATAセクション付きXMLを使用します。各ノードはトークン数、所要時間、生成統計を保存します。

- **フロー履歴の再構築**: `Flow`クラスの`convert_map()`メソッドは、DFS探索とインデントを使用して会話の分岐を視覚的に表現します。

- **インタラクティブREPL**: CLIは`/retry`、`/list`、`/flow`、`/exit`などのコマンドを持つインタラクティブモードを提供します。リトライは自動的にフローに新しい分岐を作成します。

### 現在の開発フェーズ

プロジェクトは計画された5フェーズのうちフェーズ1（コア実装）にあります。将来のフェーズでは、メタデータ管理、WebSocketサーバー、フロントエンド視覚化、高度なコンテキスト最適化が追加される予定です。